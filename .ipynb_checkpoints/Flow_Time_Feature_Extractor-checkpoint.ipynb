{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd470fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import sys\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import Workbook\n",
    "import math\n",
    "import statistics\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import xlsxwriter\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a28b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetadata(flow): \n",
    "    tmp = []\n",
    "    # inbound packets\n",
    "    if 'num_pkts_in' in flow:\n",
    "        tmp.append(flow['num_pkts_in'])\n",
    "    else:\n",
    "        tmp.append(0)\n",
    "    # outbound packets\n",
    "    if 'num_pkts_out' in flow:\n",
    "        tmp.append(flow['num_pkts_out']) \n",
    "    else:\n",
    "        tmp.append(0)\n",
    "    # inbound bytes\n",
    "    if 'bytes_in' in flow:\n",
    "        tmp.append(flow['bytes_in']) \n",
    "    else:\n",
    "        tmp.append(0)\n",
    "    # outbound bytes\n",
    "    if 'bytes_out' in flow:\n",
    "        tmp.append(flow['bytes_out']) \n",
    "    else:\n",
    "        tmp.append(0)\n",
    "    # elapsed time of flow\n",
    "    if flow['packets'] == []:\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        time = 0\n",
    "        for packet in flow['packets']:\n",
    "            time += packet['ipt']\n",
    "        tmp.append(time)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5de4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimes(flow):\n",
    "    numRows = 10\n",
    "    binSize = 50.0\n",
    "    transMat = np.zeros((numRows,numRows))\n",
    "    if len(flow['packets']) == 0:\n",
    "        return list(transMat.flatten())\n",
    "    elif len(flow['packets']) == 1:\n",
    "        cur = min(int(flow['packets'][0]['ipt']/float(binSize)), numRows-1)\n",
    "        transMat[cur, cur] = 1\n",
    "        return list(transMat.flatten())\n",
    "    # get raw transition counts\n",
    "    for i in range(1, len(flow['packets'])):\n",
    "        prev = min(int(flow['packets'][i-1]['ipt']/float(binSize)), numRows-1)\n",
    "        cur = min(int(flow['packets'][i]['ipt']/float(binSize)), numRows-1)\n",
    "#         curr=\"{:.2f}\".format(cur)\n",
    "        current=round(cur,2)\n",
    "        previous=round(prev,2)\n",
    "        transMat[previous, current] += 1\n",
    "    # get empirical transition probabilities\n",
    "    for i in range(numRows):\n",
    "        if float(np.sum(transMat[i:i+1])) != 0:\n",
    "            transMat[i:i+1] = transMat[i:i+1]/float(np.sum(transMat[i:i+1]))\n",
    "    rounded_digit= [round(num, 2) for num in list(transMat.flatten())]\n",
    "    return rounded_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd5cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLengths(flow):\n",
    "    numRows = 10\n",
    "    binSize = 150.0\n",
    "    transMat = np.zeros((numRows,numRows))\n",
    "    if len(flow['packets']) == 0:\n",
    "        return list(transMat.flatten())\n",
    "    elif len(flow['packets']) == 1:\n",
    "        cur = min(int(flow['packets'][0]['b']/float(binSize)), numRows-1)\n",
    "        transMat[cur, cur] = 1\n",
    "        return list(transMat.flatten())\n",
    "    # get raw transition counts\n",
    "    for i in range(1, len(flow['packets'])):\n",
    "        prev = min(int(flow['packets'][i-1]['b']/float(binSize)), numRows-1)\n",
    "        #if 'b' not in flow['packets'][i]:\n",
    "        #break\n",
    "        cur = min(int(flow['packets'][i]['b']/float(binSize)), numRows-1)\n",
    "        transMat[prev, cur] += 1\n",
    "    # get empirical transition probabilities\n",
    "    for i in range(numRows):\n",
    "        if float(np.sum(transMat[i:i+1])) != 0:\n",
    "            transMat[i:i+1] = transMat[i:i+1]/float(np.sum(transMat[i:i+1]))\n",
    "    rounded_digit= [round(num, 2) for num in list(transMat.flatten())]\n",
    "    return rounded_digit\n",
    "#     return list(transMat.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5ac08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getByteDist(flow):\n",
    "    if len(flow['packets']) == 0:\n",
    "        return list(np.zeros(256))\n",
    "    if 'byte_dist' in flow and sum(flow['byte_dist']) > 0:\n",
    "        tmp = map(lambda x: x/float(sum(flow['byte_dist'])), flow['byte_dist'])\n",
    "        rounded_digit= [round(num, 2) for num in list(tmp)]\n",
    "        return rounded_digit\n",
    "#         return list(tmp)\n",
    "    else:\n",
    "        return list(np.zeros(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b0f252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toExcel(data,fileName): \n",
    "#     print(os.path.splitext(fileName))\n",
    "        excel_Dir='/home/elliot/Desktop/Thesis/Main_Features/Excel_Output_Folder/'\n",
    "        filename, file_extension=os.path.splitext(fileName)\n",
    "        xlsfile = excel_Dir+filename+'.xlsx'\n",
    "        my_list = [data]\n",
    "        ex=str(xlsfile) \n",
    "        file = pathlib.Path(ex)\n",
    "    #     print(file)\n",
    "        if file.exists ():\n",
    "            wb = load_workbook(ex)\n",
    "            worksheet = wb.add_worksheet()\n",
    "            print (\"File exist\")        \n",
    "            for row_num, row_data in enumerate(my_list):\n",
    "                for col_num, col_data in enumerate(row_data):\n",
    "                    worksheet.write(row_num, col_num, col_data)\n",
    "            workbook.close()\n",
    "        else:\n",
    "#             print(\"\\nExcel File %s Created:\"%file)\n",
    "            workbook = xlsxwriter.Workbook(ex)\n",
    "            worksheet = workbook.add_worksheet()\n",
    "            for row_num, row_data in enumerate(my_list):\n",
    "                for col_num, col_data in enumerate(row_data):\n",
    "                    worksheet.write(row_num, col_num, col_data)\n",
    "            workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bb1ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessMETA(inPathName, fileName, meta):\n",
    "    json_file = \"%s%s\" % (inPathName, fileName)\n",
    "    META_JSON_Folder='/home/elliot/Desktop/Thesis/Main_Features/META_JSON/'\n",
    "#     print(json_file)\n",
    "    #read each line and convert it into dict\n",
    "    lineno = 0\n",
    "    total = 0\n",
    "    with gzip.open(json_file, 'r') as fp:\n",
    "        server_address_holder=[]\n",
    "        flowTime_Flatten=[]\n",
    "        aggregate_FT=[]\n",
    "        i=0\n",
    "        for line in fp:\n",
    "            \n",
    "            lineno = lineno + 1\n",
    "            if lineno>500000:\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    tmp = json.loads(line)\n",
    "                except:\n",
    "                    continue\n",
    "                if ('version' in tmp) or (\"tls\" not in tmp) or (int(tmp[\"dp\"]) != 443):\n",
    "                    continue\n",
    "                \n",
    "                serverAddr = \"sourceAddr=%s_sourcePort=%s_destAddr=%s\"%(tmp[\"sa\"],str(tmp[\"sp\"]),tmp[\"da\"])\n",
    "                DestIP=str(tmp[\"da\"])\n",
    "                if DestIP in server_address_holder:\n",
    "                    continue\n",
    "                else:\n",
    "                    server_address_holder.append(tmp[\"da\"])\n",
    "                    \n",
    "#                     meta[serverAddr]['count'] += 1\n",
    "                    meta[serverAddr] = defaultdict()\n",
    "                    \n",
    "                    meta[serverAddr]['flowTimes'] = getTimes(tmp)\n",
    "                    flowTime_Flatten=meta[serverAddr]['flowTimes']\n",
    "#                     print( flowTime_Flatten)\n",
    "#                     aggregate_FT.append(flowTime_Flatten)\n",
    "#                     toExcel(flowTime_Flatten,fileName)\n",
    "#                     print(\"Meta features processing\")\n",
    "#                     meta[serverAddr]['flowLengths'] = getLengths(tmp)\n",
    "#                     meta[serverAddr]['flowByteDist'] = getByteDist(tmp)\n",
    "                    i=i+1\n",
    "                    stringI=str(i)\n",
    "                    fileName, file_extension=os.path.splitext(fileName)\n",
    "                    fileNa=str(fileName+'__'+stringI)\n",
    "#                     saveToJson(META_JSON_Folder, fileNa, flowTime_Flatten)\n",
    "                    toExcel(flowTime_Flatten,fileNa)\n",
    "#                     print(len(server_address_holder))\n",
    "    print(\"Meta features processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "348ed434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToJson(outPathName, fileName, meta):\n",
    "    fname = \"%s%s.json\" % (outPathName, (fileName.split('.'))[0])  \n",
    "#     print(\"Saving JSON to \" + fname) #verbose\n",
    "#     print(fname)\n",
    "    with open(fname, \"w\") as fp:\n",
    "        json.dump(meta,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc1da0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excelAggregator():\n",
    "    cwd = os.chdir('/home/elliot/Desktop/Thesis/Main_Features/Excel_Output_Folder/')\n",
    "    Files = os.listdir('/home/elliot/Desktop/Thesis/Main_Features/Excel_Output_Folder') \n",
    "    Files.sort()\n",
    "    excel_names=[]\n",
    "    for file in Files:\n",
    "        if file.endswith('.xlsx'):\n",
    "                excel_names.append(file)\n",
    "    print(len(excel_names))\n",
    "              \n",
    "    files = os.listdir(cwd) \n",
    "    files.sort()    \n",
    "    direc='/home/elliot/Desktop/Thesis/Main_Features/Excel_Output_Folder/'\n",
    "    excels = [pd.ExcelFile(str(direc+name)) for name in excel_names]\n",
    "    frames = [x.parse(x.sheet_names[0], header=None,index_col=None) for x in excels]\n",
    "    frames[0:] = [df[0:] for df in frames[0:]]\n",
    "    combined = pd.concat(frames)\n",
    "    combined.to_excel(\"Pckt_Length_Data_Aggregated.xlsx\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b7a6d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Files : 2\n",
      "Processing Meta Feature of 2016-09-02_malware_stratosphere_miuref_0004.gzip\n",
      "Processing Meta Feature of 2016-08-04_malware_stratosphere_miuref_0003.gzip\n",
      "Flow Time Features Extracted!!\n",
      "Flow Time Features Stored in Excel\n",
      "217\n",
      "\n",
      "Process Done \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    inputF='/home/elliot/Desktop/Thesis/Main_Features/JoyOutputFolder'\n",
    "    #setup input folder and output folders\n",
    "    Files = os.listdir(inputF)\n",
    "    Files.sort()\n",
    "    json=True\n",
    "    print(\"Total Number of Files :\",len(Files))    \n",
    "    if inputF == None or not os.path.isdir(inputF):\n",
    "        print(\"No valid input folder!\")\n",
    "        return\n",
    "    else:\n",
    "        joyFolder = inputF\n",
    "        if not joyFolder.endswith('/'):\n",
    "            joyFolder += '/'\n",
    "    parentFolder = os.path.abspath(os.path.join(joyFolder, os.pardir))\n",
    "    if not parentFolder.endswith('/'):\n",
    "        parentFolder += '/'\n",
    "    META_JSON_Folder = \"%sMETA_JSON/\" % (parentFolder)\n",
    "    if not os.path.exists(META_JSON_Folder):\n",
    "        os.mkdir(META_JSON_Folder)\n",
    "    if json == True:\n",
    "        files = os.listdir(joyFolder)\n",
    "        for item in files:\n",
    "            try:\n",
    "                meta = defaultdict()\n",
    "                print(\"Processing Meta Feature of %s\"%item)\n",
    "                ProcessMETA(joyFolder, item, meta) \n",
    "#                 saveToJson(META_JSON_Folder, item, meta)\n",
    "#                 print(meta)\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        print(\"Nothing to do!\")\n",
    "        return\n",
    "    print(\"Flow Time Features Extracted!!\")\n",
    "    print(\"Flow Time Features Stored in Excel\")\n",
    "    excelAggregator()\n",
    "    print(\"\\nProcess Done \")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f649ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d1f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3df86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
